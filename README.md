# 对抗性数据改写在欺诈对话检测中的应用

## 项目概述

本项目实现了一个基于RoBERTa的欺诈对话检测系统，结合对抗性数据改写技术提升模型的鲁棒性。系统采用上下文感知的对抗攻击方法，针对诈骗者的对话内容进行语义保留的改写，生成对抗样本，并通过对抗性训练增强模型对欺诈对话的检测能力。

## 主要功能

### 1. 数据处理模块 (DataProcessor)

- 读取并清洗CSV格式的对话数据
- 处理标签转换（True/False → 1/0）
- 文本预处理和规范化
- 数据集统计信息展示

### 2. 对抗攻击/改写模块 (AdversarialRewriter)

- 基于Masked Language Model实现上下文感知的文本改写
- 选择性攻击策略：仅针对诈骗者（"left:"）的对话内容进行改写
- 保留原始语义的同时改变关键词，生成对抗样本
- 智能过滤：避免替换标点符号，确保生成文本的可读性

### 3. 模型训练与评估模块

- 使用hfl/chinese-roberta-wwm-ext作为预训练模型
- 实现基线模型训练和评估
- 对抗性训练以增强模型鲁棒性
- 多维度评估指标：准确率、精确率、召回率和F1分数

## 技术栈

- Python 3.8+
- PyTorch 1.10+
- Transformers (Hugging Face)
- Pandas
- scikit-learn
- NumPy

## 环境要求

```bash
# 核心依赖
pip install transformers>=4.28.0
pip install accelerate>=0.26.0
pip install torch>=1.10.0
pip install pandas
pip install scikit-learn
pip install numpy
```

## 数据准备

项目需要在`Dataset`目录下准备训练集和测试集：

**数据格式要求：**

- 必须包含列：`specific_dialogue_content`（对话内容）和`is_fraud`（标签）
- 可选列：`fraud_type`（欺诈类型）
- 对话格式：使用`left:`和`right:`标识对话双方

## 使用方法

### 1. 直接运行主脚本

```bash
cd work
python RoBERTa.py
```

脚本会自动执行完整的训练和评估流程，包括：

- 依赖检查和安装
- 基线模型训练
- 对抗样本生成
- 对抗性训练
- 多维度性能评估

### 2. 自定义参数

可以在代码中调整以下关键参数：

- 批量大小：`per_device_train_batch_size=16`, `per_device_eval_batch_size=32`
- 训练轮次：`num_train_epochs=3`
- 学习率：`learning_rate=2e-5`
- 序列长度：`max_length=256`
- 对抗攻击替换比例：`replace_ratio=0.15`

## 实验流程

1. **基线模型训练**：使用原始训练集训练分类模型
2. **对抗样本生成**：对测试集生成对抗样本，评估基线模型的鲁棒性
3. **对抗性训练**：将原始训练集与对抗样本合并进行再训练
4. **最终评估**：测试鲁棒模型在对抗样本上的性能

## 输出结果

### 控制台输出

- 数据集统计信息
- 模型训练进度和日志
- 评估指标（准确率、F1分数、精确率、召回率）

### 文件输出

- **模型检查点**：保存至`./results_baseline/`和`./results_robust/`目录
- 每个检查点包含完整的模型权重、分词器和训练配置

## RTX 4060 GPU优化

代码已针对RTX 4060 GPU进行优化，包括：

- 混合精度训练（fp16=True）
- 梯度累积（gradient_accumulation_steps=2）
- 动态padding以节省显存
- 适当的批量大小设置
- 内存管理和清理

## 实验结果解释

系统会输出三个关键评估结果：

1. **基线模型在原始测试集上的表现**：反映模型基础能力
2. **基线模型在对抗测试集上的表现**：评估模型对对抗攻击的脆弱性
3. **对抗训练后模型在对抗测试集上的表现**：验证对抗训练的有效性

如果对抗训练后的模型在对抗测试集上的性能优于基线模型，说明对抗性训练成功提升了模型的鲁棒性。

## 注意事项

- 首次运行会自动下载预训练模型，可能需要一些时间
- 训练过程需要GPU支持，在没有GPU的环境下会非常缓慢
- 对抗样本生成是计算密集型任务，可能需要较长时间
- 确保数据集格式正确，避免运行时错误

## 故障排除

- **内存错误**：尝试减小批量大小或序列长度
- **依赖问题**：使用代码中提供的`check_dependencies()`函数自动安装/更新依赖
- **Triton错误**：代码已禁用`torch.compile`，避免Triton依赖问题

## 扩展与改进方向

1. 实现更多样化的对抗攻击方法
2. 引入模型蒸馏以减小模型大小
3. 添加早停机制避免过拟合
4. 实现更细粒度的欺诈类型分类
5. 开发Web界面进行交互式预测
